{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralStyleTransfer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kennybobboy/ML1-5/blob/master/NeuralStyleTransfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6uFMHf2tUPi",
        "colab_type": "text"
      },
      "source": [
        "https://github.com/ericjjj/coursera/blob/master/05-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-Convolutional%20Neural%20Networks/04-Art%2BGeneration%2Bwith%2BNeural%2BStyle%2BTransfer%2B-%2Bv2.ipynb\n",
        "This is a link to the details given to follow the program below. Please reference this link for more information on the program."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3h4_hkEY_pA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import scipy.io\n",
        "import scipy.misc\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "from PIL import Image\n",
        "#from nst_utils import *\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9touRYXFs8o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://github.com/JudasDie/deeplearning.ai/blob/master/Convolutional%20Neural%20Networks/week4/ArtTrans/nst_utils.py\n",
        "import os\n",
        "import sys\n",
        "import scipy.io\n",
        "import scipy.misc\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "from PIL import Image\n",
        "#from nst_utils import *\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "class CONFIG:\n",
        "    IMAGE_WIDTH = 400\n",
        "    IMAGE_HEIGHT = 300\n",
        "    COLOR_CHANNELS = 3\n",
        "    NOISE_RATIO = 0.6\n",
        "    MEANS = np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3)) \n",
        "    VGG_MODEL = 'pretrained-model/imagenet-vgg-verydeep-19.mat' # Pick the VGG 19-layer model by from the paper \"Very Deep Convolutional Networks for Large-Scale Image Recognition\".\n",
        "    STYLE_IMAGE = 'images/stone_style.jpg' # Style image to use.\n",
        "    CONTENT_IMAGE = 'images/content300.jpg' # Content image to use.\n",
        "    OUTPUT_DIR = 'output/'\n",
        "    \n",
        "def load_vgg_model(path):\n",
        "    \"\"\"\n",
        "    Returns a model for the purpose of 'painting' the picture.\n",
        "    Takes only the convolution layer weights and wrap using the TensorFlow\n",
        "    Conv2d, Relu and AveragePooling layer. VGG actually uses maxpool but\n",
        "    the paper indicates that using AveragePooling yields better results.\n",
        "    The last few fully connected layers are not used.\n",
        "    Here is the detailed configuration of the VGG model:\n",
        "        0 is conv1_1 (3, 3, 3, 64)\n",
        "        1 is relu\n",
        "        2 is conv1_2 (3, 3, 64, 64)\n",
        "        3 is relu    \n",
        "        4 is maxpool\n",
        "        5 is conv2_1 (3, 3, 64, 128)\n",
        "        6 is relu\n",
        "        7 is conv2_2 (3, 3, 128, 128)\n",
        "        8 is relu\n",
        "        9 is maxpool\n",
        "        10 is conv3_1 (3, 3, 128, 256)\n",
        "        11 is relu\n",
        "        12 is conv3_2 (3, 3, 256, 256)\n",
        "        13 is relu\n",
        "        14 is conv3_3 (3, 3, 256, 256)\n",
        "        15 is relu\n",
        "        16 is conv3_4 (3, 3, 256, 256)\n",
        "        17 is relu\n",
        "        18 is maxpool\n",
        "        19 is conv4_1 (3, 3, 256, 512)\n",
        "        20 is relu\n",
        "        21 is conv4_2 (3, 3, 512, 512)\n",
        "        22 is relu\n",
        "        23 is conv4_3 (3, 3, 512, 512)\n",
        "        24 is relu\n",
        "        25 is conv4_4 (3, 3, 512, 512)\n",
        "        26 is relu\n",
        "        27 is maxpool\n",
        "        28 is conv5_1 (3, 3, 512, 512)\n",
        "        29 is relu\n",
        "        30 is conv5_2 (3, 3, 512, 512)\n",
        "        31 is relu\n",
        "        32 is conv5_3 (3, 3, 512, 512)\n",
        "        33 is relu\n",
        "        34 is conv5_4 (3, 3, 512, 512)\n",
        "        35 is relu\n",
        "        36 is maxpool\n",
        "        37 is fullyconnected (7, 7, 512, 4096)\n",
        "        38 is relu\n",
        "        39 is fullyconnected (1, 1, 4096, 4096)\n",
        "        40 is relu\n",
        "        41 is fullyconnected (1, 1, 4096, 1000)\n",
        "        42 is softmax\n",
        "    \"\"\"\n",
        "    \n",
        "    vgg = scipy.io.loadmat(path)\n",
        "\n",
        "    vgg_layers = vgg['layers']\n",
        "    \n",
        "    def _weights(layer, expected_layer_name):\n",
        "        \"\"\"\n",
        "        Return the weights and bias from the VGG model for a given layer.\n",
        "        \"\"\"\n",
        "        wb = vgg_layers[0][layer][0][0][2]\n",
        "        W = wb[0][0]\n",
        "        b = wb[0][1]\n",
        "        layer_name = vgg_layers[0][layer][0][0][0][0]\n",
        "        assert layer_name == expected_layer_name\n",
        "        return W, b\n",
        "\n",
        "        #return W, b\n",
        "\n",
        "    def _relu(conv2d_layer):\n",
        "        \"\"\"\n",
        "        Return the RELU function wrapped over a TensorFlow layer. Expects a\n",
        "        Conv2d layer input.\n",
        "        \"\"\"\n",
        "        return tf.nn.relu(conv2d_layer)\n",
        "\n",
        "    def _conv2d(prev_layer, layer, layer_name):\n",
        "        \"\"\"\n",
        "        Return the Conv2D layer using the weights, biases from the VGG\n",
        "        model at 'layer'.\n",
        "        \"\"\"\n",
        "        W, b = _weights(layer, layer_name)\n",
        "        W = tf.constant(W) # Made dtype=tf.float32 KWB 1/28/2019\n",
        "        #print(prev_layer)\n",
        "        #print(W)\n",
        "        b = tf.constant(np.reshape(b, len(b)))\n",
        "        return tf.nn.conv2d(prev_layer, filter=W, strides=[1, 1, 1, 1], padding='SAME') + b\n",
        "\n",
        "    def _conv2d_relu(prev_layer, layer, layer_name):\n",
        "        \"\"\"\n",
        "        Return the Conv2D + RELU layer using the weights, biases from the VGG\n",
        "        model at 'layer'.\n",
        "        \"\"\"\n",
        "        return _relu(_conv2d(prev_layer, layer, layer_name))\n",
        "\n",
        "    def _avgpool(prev_layer):\n",
        "        \"\"\"\n",
        "        Return the AveragePooling layer.\n",
        "        \"\"\"\n",
        "        return tf.nn.avg_pool(prev_layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
        "\n",
        "    # Constructs the graph model.\n",
        "    graph = {}\n",
        "    graph['input']   = tf.Variable(np.zeros((1, CONFIG.IMAGE_HEIGHT, CONFIG.IMAGE_WIDTH, CONFIG.COLOR_CHANNELS)), dtype = 'float32')\n",
        "    graph['conv1_1']  = _conv2d_relu(graph['input'], 0, 'conv1_1')\n",
        "    graph['conv1_2']  = _conv2d_relu(graph['conv1_1'], 2, 'conv1_2')\n",
        "    graph['avgpool1'] = _avgpool(graph['conv1_2'])\n",
        "    graph['conv2_1']  = _conv2d_relu(graph['avgpool1'], 5, 'conv2_1')\n",
        "    graph['conv2_2']  = _conv2d_relu(graph['conv2_1'], 7, 'conv2_2')\n",
        "    graph['avgpool2'] = _avgpool(graph['conv2_2'])\n",
        "    graph['conv3_1']  = _conv2d_relu(graph['avgpool2'], 10, 'conv3_1')\n",
        "    graph['conv3_2']  = _conv2d_relu(graph['conv3_1'], 12, 'conv3_2')\n",
        "    graph['conv3_3']  = _conv2d_relu(graph['conv3_2'], 14, 'conv3_3')\n",
        "    graph['conv3_4']  = _conv2d_relu(graph['conv3_3'], 16, 'conv3_4')\n",
        "    graph['avgpool3'] = _avgpool(graph['conv3_4'])\n",
        "    graph['conv4_1']  = _conv2d_relu(graph['avgpool3'], 19, 'conv4_1')\n",
        "    graph['conv4_2']  = _conv2d_relu(graph['conv4_1'], 21, 'conv4_2')\n",
        "    graph['conv4_3']  = _conv2d_relu(graph['conv4_2'], 23, 'conv4_3')\n",
        "    graph['conv4_4']  = _conv2d_relu(graph['conv4_3'], 25, 'conv4_4')\n",
        "    graph['avgpool4'] = _avgpool(graph['conv4_4'])\n",
        "    graph['conv5_1']  = _conv2d_relu(graph['avgpool4'], 28, 'conv5_1')\n",
        "    graph['conv5_2']  = _conv2d_relu(graph['conv5_1'], 30, 'conv5_2')\n",
        "    graph['conv5_3']  = _conv2d_relu(graph['conv5_2'], 32, 'conv5_3')\n",
        "    graph['conv5_4']  = _conv2d_relu(graph['conv5_3'], 34, 'conv5_4')\n",
        "    graph['avgpool5'] = _avgpool(graph['conv5_4'])\n",
        "    \n",
        "    return graph\n",
        "\n",
        "def generate_noise_image(content_image, noise_ratio = CONFIG.NOISE_RATIO):\n",
        "    \"\"\"\n",
        "    Generates a noisy image by adding random noise to the content_image\n",
        "    \"\"\"\n",
        "    \n",
        "    # Generate a random noise_image\n",
        "    noise_image = np.random.uniform(-20, 20, (1, CONFIG.IMAGE_HEIGHT, CONFIG.IMAGE_WIDTH, CONFIG.COLOR_CHANNELS)).astype('float32')\n",
        "    \n",
        "    # Set the input_image to be a weighted average of the content_image and a noise_image\n",
        "    input_image = noise_image * noise_ratio + content_image * (1 - noise_ratio)\n",
        "    \n",
        "    return input_image\n",
        "\n",
        "\n",
        "def reshape_and_normalize_image(image):\n",
        "    \"\"\"\n",
        "    Reshape and normalize the input image (content or style)\n",
        "    \"\"\"\n",
        "    \n",
        "    # Reshape image to mach expected input of VGG16\n",
        "    image = np.reshape(image, ((1,) + image.shape))\n",
        "    \n",
        "    # Substract the mean to match the expected input of VGG16\n",
        "    image = image - CONFIG.MEANS\n",
        "    \n",
        "    return image\n",
        "\n",
        "\n",
        "def save_image(path, image):\n",
        "    \n",
        "    # Un-normalize the image so that it looks good\n",
        "    image = image + CONFIG.MEANS\n",
        "    \n",
        "    # Clip and Save the image\n",
        "    image = np.clip(image[0], 0, 255).astype('uint8')\n",
        "    scipy.misc.imsave(path, image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_qEBj3_HdLQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!wget -NS \"http://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat\"\n",
        "!wget -NS \"http://www.vlfeat.org/matconvnet/models/imagenet-vgg-verydeep-19.mat\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLcEVh76ZOxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_vgg_model(\"imagenet-vgg-verydeep-19.mat\")\n",
        "#print(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "129OkZouZWpA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -NS \"https://raw.githubusercontent.com/enggen/Deep-Learning-Coursera/master/Convolutional%20Neural%20Networks/Week4/Neural%20Style%20Transfer/images/louvre.jpg\"\n",
        "content_image = scipy.misc.imread(\"louvre.jpg\")\n",
        "imshow(content_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qi2F9C-8ZdYf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GRADED FUNCTION: compute_content_cost\n",
        "\n",
        "def compute_content_cost(a_C, a_G):\n",
        "    \"\"\"\n",
        "    Computes the content cost\n",
        "    \n",
        "    Arguments:\n",
        "    a_C -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image C \n",
        "    a_G -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image G\n",
        "    \n",
        "    Returns: \n",
        "    J_content -- scalar that you compute using equation 1 above.\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    # Retrieve dimensions from a_G (≈1 line)\n",
        "    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n",
        "    \n",
        "    # Reshape a_C and a_G (≈2 lines)\n",
        "    a_C_unrolled = tf.transpose(tf.reshape(a_C,(n_H*n_W,n_C)))\n",
        "    a_G_unrolled = tf.transpose(tf.reshape(a_G,(n_H*n_W,n_C)))\n",
        "    \n",
        "    # compute the cost with tensorflow (≈1 line)\n",
        "    J_content = (1/(4 * n_H * n_W * n_C)) * tf.reduce_sum(tf.square(tf.subtract(a_C, a_G)))\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return J_content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldEoE-zRZjZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "with tf.Session() as test:\n",
        "    tf.set_random_seed(1)\n",
        "    a_C = tf.random_normal([1, 4, 4, 3], mean=1, stddev=4)\n",
        "    a_G = tf.random_normal([1, 4, 4, 3], mean=1, stddev=4)\n",
        "    J_content = compute_content_cost(a_C, a_G)\n",
        "    print(\"J_content = \" + str(J_content.eval()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0X3_o1WYZoOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -NS \"https://raw.githubusercontent.com/enggen/Deep-Learning-Coursera/master/Convolutional%20Neural%20Networks/Week4/Neural%20Style%20Transfer/images/monet_800600.jpg\"\n",
        "style_image = scipy.misc.imread(\"monet_800600.jpg\")\n",
        "imshow(style_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sV9c_CItZuZs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GRADED FUNCTION: gram_matrix\n",
        "\n",
        "def gram_matrix(A):\n",
        "    \"\"\"\n",
        "    Argument:\n",
        "    A -- matrix of shape (n_C, n_H*n_W)\n",
        "    \n",
        "    Returns:\n",
        "    GA -- Gram matrix of A, of shape (n_C, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ### (≈1 line)\n",
        "    GA = tf.matmul(A,A, transpose_b=True)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return GA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAbtH45yZ0Ry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "with tf.Session() as test:\n",
        "    tf.set_random_seed(1)\n",
        "    A = tf.random_normal([3, 2*1], mean=1, stddev=4)\n",
        "    GA = gram_matrix(A)\n",
        "    \n",
        "    print(\"GA = \" + str(GA.eval()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kuf5Hru_Z4Y4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GRADED FUNCTION: compute_layer_style_cost\n",
        "\n",
        "def compute_layer_style_cost(a_S, a_G):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    a_S -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing style of the image S \n",
        "    a_G -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing style of the image G\n",
        "    \n",
        "    Returns: \n",
        "    J_style_layer -- tensor representing a scalar value, style cost defined above by equation (2)\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    # Retrieve dimensions from a_G (≈1 line)\n",
        "    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n",
        "    \n",
        "    # Reshape the images to have them of shape (n_C, n_H*n_W) (≈2 lines)\n",
        "    a_S = tf.transpose(tf.reshape(a_S,(n_H*n_W,n_C)))\n",
        "    a_G = tf.transpose(tf.reshape(a_G,(n_H*n_W,n_C)))\n",
        "\n",
        "    # Computing gram_matrices for both images S and G (≈2 lines)\n",
        "    GS = gram_matrix(a_S)\n",
        "    GG = gram_matrix(a_G)\n",
        "\n",
        "    # Computing the loss (≈1 line)\n",
        "    J_style_layer = (1/(4 * np.square(n_C) * np.square(n_H * n_W))) * tf.reduce_sum(tf.square(tf.subtract(GS,GG)))\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return J_style_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0E031OAZ_9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "with tf.Session() as test:\n",
        "    tf.set_random_seed(1)\n",
        "    a_S = tf.random_normal([1, 4, 4, 3], mean=1, stddev=4)\n",
        "    a_G = tf.random_normal([1, 4, 4, 3], mean=1, stddev=4)\n",
        "    J_style_layer = compute_layer_style_cost(a_S, a_G)\n",
        "    \n",
        "    print(\"J_style_layer = \" + str(J_style_layer.eval()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgBjV9lnaFar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STYLE_LAYERS = [\n",
        "    ('conv1_1', 0.2),\n",
        "    ('conv2_1', 0.2),\n",
        "    ('conv3_1', 0.2),\n",
        "    ('conv4_1', 0.2),\n",
        "    ('conv5_1', 0.2)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKEk1q6zaK4J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_style_cost(model, STYLE_LAYERS):\n",
        "    \"\"\"\n",
        "    Computes the overall style cost from several chosen layers\n",
        "    \n",
        "    Arguments:\n",
        "    model -- our tensorflow model\n",
        "    STYLE_LAYERS -- A python list containing:\n",
        "                        - the names of the layers we would like to extract style from\n",
        "                        - a coefficient for each of them\n",
        "    \n",
        "    Returns: \n",
        "    J_style -- tensor representing a scalar value, style cost defined above by equation (2)\n",
        "    \"\"\"\n",
        "    \n",
        "    # initialize the overall style cost\n",
        "    J_style = 0\n",
        "\n",
        "    for layer_name, coeff in STYLE_LAYERS:\n",
        "\n",
        "        # Select the output tensor of the currently selected layer\n",
        "        out = model[layer_name]\n",
        "\n",
        "        # Set a_S to be the hidden layer activation from the layer we have selected, by running the session on out\n",
        "        a_S = sess.run(out)\n",
        "\n",
        "        # Set a_G to be the hidden layer activation from same layer. Here, a_G references model[layer_name] \n",
        "        # and isn't evaluated yet. Later in the code, we'll assign the image G as the model input, so that\n",
        "        # when we run the session, this will be the activations drawn from the appropriate layer, with G as input.\n",
        "        a_G = out\n",
        "        \n",
        "        # Compute style_cost for the current layer\n",
        "        J_style_layer = compute_layer_style_cost(a_S, a_G)\n",
        "\n",
        "        # Add coeff * J_style_layer of this layer to overall style cost\n",
        "        J_style += coeff * J_style_layer\n",
        "\n",
        "    return J_style"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwSrbz7caPqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GRADED FUNCTION: total_cost\n",
        "\n",
        "def total_cost(J_content, J_style, alpha = 10, beta = 40):\n",
        "    \"\"\"\n",
        "    Computes the total cost function\n",
        "    \n",
        "    Arguments:\n",
        "    J_content -- content cost coded above\n",
        "    J_style -- style cost coded above\n",
        "    alpha -- hyperparameter weighting the importance of the content cost\n",
        "    beta -- hyperparameter weighting the importance of the style cost\n",
        "    \n",
        "    Returns:\n",
        "    J -- total cost as defined by the formula above.\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ### (≈1 line)\n",
        "    J = alpha * J_content + beta * J_style\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return J"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7g-Oy6eUaWMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "with tf.Session() as test:\n",
        "    np.random.seed(3)\n",
        "    J_content = np.random.randn()    \n",
        "    J_style = np.random.randn()\n",
        "    J = total_cost(J_content, J_style)\n",
        "    print(\"J = \" + str(J))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDkMVPDfabRs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reset the graph\n",
        "tf.reset_default_graph()\n",
        "\n",
        "# Start interactive session\n",
        "sess = tf.InteractiveSession()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mk1fcLiDaim9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -NS \"https://raw.githubusercontent.com/enggen/Deep-Learning-Coursera/master/Convolutional%20Neural%20Networks/Week4/Neural%20Style%20Transfer/images/louvre_small.jpg\"\n",
        "content_image = scipy.misc.imread(\"louvre_small.jpg\")\n",
        "content_image = reshape_and_normalize_image(content_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNS5P7jFaoTL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -NS \"https://raw.githubusercontent.com/enggen/Deep-Learning-Coursera/master/Convolutional%20Neural%20Networks/Week4/Neural%20Style%20Transfer/images/monet.jpg\"\n",
        "style_image = scipy.misc.imread(\"monet.jpg\")\n",
        "style_image = reshape_and_normalize_image(style_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DpTmwkcasGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generated_image = generate_noise_image(content_image)\n",
        "imshow(generated_image[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbsiBl6BaxHV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_vgg_model(\"imagenet-vgg-verydeep-19.mat\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXhOPMPNa2aS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Assign the content image to be the input of the VGG model.  \n",
        "sess.run(model['input'].assign(content_image))\n",
        "\n",
        "# Select the output tensor of layer conv4_2\n",
        "out = model['conv4_2']\n",
        "\n",
        "# Set a_C to be the hidden layer activation from the layer we have selected\n",
        "a_C = sess.run(out)\n",
        "\n",
        "# Set a_G to be the hidden layer activation from same layer. Here, a_G references model['conv4_2'] \n",
        "# and isn't evaluated yet. Later in the code, we'll assign the image G as the model input, so that\n",
        "# when we run the session, this will be the activations drawn from the appropriate layer, with G as input.\n",
        "a_G = out\n",
        "\n",
        "# Compute the content cost\n",
        "J_content = compute_content_cost(a_C, a_G)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyAeCuOAa8C4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Assign the input of the model to be the \"style\" image \n",
        "sess.run(model['input'].assign(style_image))\n",
        "\n",
        "# Compute the style cost\n",
        "J_style = compute_style_cost(model, STYLE_LAYERS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8kyRj95bAQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### START CODE HERE ### (1 line)\n",
        "J = total_cost(J_content, J_style,alpha=10,beta=40)\n",
        "### END CODE HERE ###"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeJMOgEEbGMr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define optimizer (1 line)\n",
        "optimizer = tf.train.AdamOptimizer(2.0)\n",
        "\n",
        "# define train_step (1 line)\n",
        "train_step = optimizer.minimize(J)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytL1ZnzDbKVY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_nn(sess, input_image, num_iterations = 200):\n",
        "    \n",
        "    # Initialize global variables (you need to run the session on the initializer)\n",
        "    ### START CODE HERE ### (1 line)\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Run the noisy input image (initial generated image) through the model. Use assign().\n",
        "    ### START CODE HERE ### (1 line)\n",
        "    sess.run(model[\"input\"].assign(input_image))\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    for i in range(num_iterations):\n",
        "    \n",
        "        # Run the session on the train_step to minimize the total cost\n",
        "        ### START CODE HERE ### (1 line)\n",
        "        sess.run(train_step)\n",
        "        ### END CODE HERE ###\n",
        "        \n",
        "        # Compute the generated image by running the session on the current model['input']\n",
        "        ### START CODE HERE ### (1 line)\n",
        "        generated_image = sess.run(model[\"input\"])\n",
        "        ### END CODE HERE ###\n",
        "\n",
        "        # Print every 20 iteration.\n",
        "        if i%20 == 0:\n",
        "            Jt, Jc, Js = sess.run([J, J_content, J_style])\n",
        "            print(\"Iteration \" + str(i) + \" :\")\n",
        "            print(\"total cost = \" + str(Jt))\n",
        "            print(\"content cost = \" + str(Jc))\n",
        "            print(\"style cost = \" + str(Js))\n",
        "            \n",
        "            # save current generated image in the \"/output\" directory\n",
        "            save_image(str(i) + \".png\", generated_image)\n",
        "    \n",
        "    # save last generated image\n",
        "    save_image('generated_image.jpg', generated_image)\n",
        "    \n",
        "    return generated_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8HPv0WrbPoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_nn(sess, generated_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFcD3R3a_Xwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "content_image = scipy.misc.imread(\"generated_image.jpg\")\n",
        "imshow(content_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e1-mL86bWLw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}